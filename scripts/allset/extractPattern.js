const { trim } = require('../scriptUtils');
const uniq = require('lodash.uniq');

const AUTOGEN_COMMENT = trim(`
/* --- AUTOGENERATED FILE -----------------------------
* If you make changes to this file delete this comment.
* Otherwise the file may be overwritten in the future.
* --------------------------------------------------- */
`);

const formatStr = str =>
  !str
    ? str
    : JSON.stringify(trim(str))
        .replace(/\\"/g, '"')
        .replace(/'/g, "\\'")
        .replace(/^"|"$/g, '');

const getExamplesString = exampleFields => {
  const strings = exampleFields.map(field =>
    trim(`
    {
      zh: '${formatStr(field.zh)}',
      en: '${formatStr(field.en)}',
      src: allSetSrc,
    },
  `)
  );
  return strings.join('\n    ');
};

module.exports = (fields, options = {}) => {
  const { matcherId, name, examples, description, url, regexes } = fields;
  const useRegexTokensMatch = options.regexTokensMatch;
  const useGraphMatch = options.graphMatch;
  const useRegexLocsMatch =
    options.regexLocsMatch || !(useGraphMatch || useRegexTokensMatch);

  const fullPatternName = `${matcherId}Pattern`;

  const matchRegexStrings = regexes.map(
    regex => `regexMatchLocs(sentence.text, ${regex}),`
  );

  const examplesString = getExamplesString(examples);

  const imports = [`const { mergeLocMatchGroups } = require('../lib/matching/utils');`];
  if (useGraphMatch) {
    imports.push(`const { and, pos, word } = require('../lib/tokenFilters');`);
    imports.push(
      `const { Node, Edge, graphMatch } = require('../lib/matching/graphMatch');`
    );
  }
  if (useRegexLocsMatch) {
    imports.push(`const { regexMatchLocs } = require('../lib/matching/regexMatch');`);
  }
  if (useRegexTokensMatch) {
    imports.push(`const { and, pos, word } = require('../lib/tokenFilters');`);
    imports.push(`const { regexMatchTokens } = require('../lib/matching/regexMatch');`);
    imports.shift();
    imports.push(
      `const { mergeLocMatchGroups, locsFromTokens } = require('../lib/matching/utils');`
    );
  }
  const importsStr = uniq(imports).join('\n');

  const matchStrings = [];
  if (useGraphMatch) {
    matchStrings.push(
      trim(`
      graphMatch(
        sentence.tokens,
        new Node({ filter: pos('TBD') }, [
          new Edge({ type: 'TDB' },
            new Node({ filter: and(pos('TBD'), word('TBD')), capture: true })
          ),
        ])
      ),
    `)
    );
  }
  if (useRegexLocsMatch) {
    matchStrings.push(matchRegexStrings.join('\n      '));
  }
  if (useRegexTokensMatch) {
    matchStrings.push(
      trim(`
      locsFromTokens(
        regexMatchTokens(
          sentence.tokens,
          '(:thing:)',
          {
            thing: and(pos('TBD'), word('TBD')),
          }
        ),
      ),
    `)
    );
  }

  const mainTemplate = trim(`
${options.skipComment ? '' : AUTOGEN_COMMENT}

${importsStr}

const allSetSrc = {
  type: 'website',
  url: '${formatStr(url)}',
  name: 'AllSet Chinese Grammar Wiki',
};


module.exports = {
  id: '${formatStr(matcherId)}',
  name: '${formatStr(name)}',
  description: '${formatStr(trim(description))}',
  sources: [
    allSetSrc,
  ],
  match: sentence => 
    mergeLocMatchGroups([
      ${matchStrings.join('\n      ')}
    ]),
  examples: [
    ${trim(examplesString)}
  ],
};
  `);

  const testTemplate = `
${AUTOGEN_COMMENT}

const ${fullPatternName} = require('./${fullPatternName}');
const {
  assertAllExamplesMatch,
  assertNoneMatch,
} = require('../lib/testUtils');

test('matches all examples', async () => {
  await assertAllExamplesMatch(${fullPatternName});
});

// TODO: Add more tests

test("doesn't match negative examples", async () => {
  await assertNoneMatch(${fullPatternName}, [
    // TODO: add negative examples here
  ]);
});
  `;

  return {
    fullPatternName,
    mainTemplate,
    testTemplate,
  };
};
